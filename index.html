<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI English Coach</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap');
        body {
            font-family: 'Inter', sans-serif;
            background-color: #f7f9fb;
        }
        .container {
            max-width: 900px;
            margin: auto;
        }
        .card {
            background-color: white;
            border-radius: 1rem;
            box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -2px rgba(0, 0, 0, 0.06);
            padding: 1.5rem;
        }
        .btn-primary {
            background-color: #3b82f6; /* Blue 500 */
            color: white;
            transition: background-color 0.2s;
        }
        .btn-primary:hover {
            background-color: #2563eb; /* Blue 600 */
        }
        .btn-record {
            background-color: #ef4444; /* Red 500 */
        }
        .btn-record:hover {
            background-color: #dc2626; /* Red 600 */
        }
        .btn-stop {
            background-color: #f59e0b; /* Amber 500 */
        }
        .btn-stop:hover {
            background-color: #d97706; /* Amber 600 */
        }
        .recording-active {
            animation: pulse-red 1.5s infinite;
        }
        @keyframes pulse-red {
            0%, 100% { box-shadow: 0 0 0 0 rgba(239, 68, 68, 0.7); }
            50% { box-shadow: 0 0 0 10px rgba(239, 68, 68, 0); }
        }
        .loader {
            border: 4px solid #f3f3f3;
            border-top: 4px solid #3b82f6;
            border-radius: 50%;
            width: 20px;
            height: 20px;
            animation: spin 1s linear infinite;
        }
        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }
    </style>
</head>
<body class="p-4 sm:p-8 min-h-screen">

    <!-- Header -->
    <header class="text-center mb-8">
        <h1 class="text-3xl sm:text-4xl font-bold text-gray-800">üó£Ô∏è AI English Pronunciation Coach</h1>
        <p class="text-gray-500 mt-2">Practice speaking and get instant, detailed accent feedback from AI.</p>
        <p id="status-message" class="mt-4 text-sm font-medium text-gray-700"></p>
    </header>

    <div class="container space-y-8">

        <!-- Section 1: AI Speaks (TTS) -->
        <div class="card">
            <h2 class="text-2xl font-semibold text-gray-800 mb-4 flex items-center">
                <svg xmlns="http://www.w3.org/2000/svg" class="h-6 w-6 mr-2 text-indigo-500" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2"><path stroke-linecap="round" stroke-linejoin="round" d="M15.536 8.464a5 5 0 010 7.072m2.121-7.072a8 8 0 010 11.314m-12.728-2.828l.707.707.707-.707m-1.414 1.414l.707.707.707-.707m-1.414 1.414l.707.707.707-.707M12 21V3m-4 8h8"/></svg>
                1. AI Says, You Listen
            </h2>
            <p class="text-gray-600 mb-4">Type a sentence below, and the AI will pronounce it clearly. You can try different voices!</p>

            <textarea id="tts-input" rows="3" class="w-full p-3 border border-gray-300 rounded-lg focus:ring-blue-500 focus:border-blue-500" placeholder="e.g., The quick brown fox jumps over the lazy dog."></textarea>

            <div class="flex flex-col sm:flex-row space-y-2 sm:space-y-0 sm:space-x-4 mt-4 items-center">
                <select id="voice-select" class="p-2 border border-gray-300 rounded-lg bg-white w-full sm:w-auto">
                    <option value="Kore">Kore (Clear)</option>
                    <option value="Zephyr">Zephyr (Bright)</option>
                    <option value="Puck">Puck (Upbeat)</option>
                    <option value="Charon">Charon (Informative)</option>
                    <option value="Leda">Leda (Youthful)</option>
                </select>
                <button id="tts-button" class="btn-primary flex items-center justify-center font-bold px-6 py-2 rounded-lg w-full sm:w-auto" onclick="speakText()">
                    <span id="tts-loader" class="hidden loader mr-2"></span>
                    <svg id="tts-icon" xmlns="http://www.w3.org/2000/svg" class="h-5 w-5 mr-2" viewBox="0 0 20 20" fill="currentColor"><path fill-rule="evenodd" d="M18 5v8a2 2 0 01-2 2h-5l-4 4v-4H4a2 2 0 01-2-2V5a2 2 0 012-2h12a2 2 0 012 2zM7 8a1 1 0 012 0v2a1 1 0 11-2 0V8zm5-1a1 1 0 00-1 1v2a1 1 0 102 0V8a1 1 0 00-1-1z" clip-rule="evenodd"/></svg>
                    <span>Read Aloud</span>
                </button>
            </div>
        </div>

        <!-- Section 2: User Speaks (ASR & Correction) -->
        <div class="card">
            <h2 class="text-2xl font-semibold text-gray-800 mb-4 flex items-center">
                <svg xmlns="http://www.w3.org/2000/svg" class="h-6 w-6 mr-2 text-green-500" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2"><path stroke-linecap="round" stroke-linejoin="round" d="M19 11a7 7 0 01-7 7m0 0a7 7 0 01-7-7m7 7v4m0 0H8m4 0h4m-4-8a1 1 0 01-1-1v-2a1 1 0 011-1m0 4a1 1 0 001-1v-2a1 1 0 00-1-1m-1 4v2a1 1 0 001 1h2a1 1 0 001-1v-2a1 1 0 00-1-1h-2z"/></svg>
                2. You Speak, AI Corrects
            </h2>
            <p class="text-gray-600 mb-4">Record yourself speaking a phrase. The AI will analyze your accent, transcribe what it heard, and suggest improvements.</p>

            <div class="flex space-x-4 items-center mb-4">
                <button id="record-button" class="btn-record flex items-center justify-center font-bold px-6 py-2 rounded-lg transition-all" onclick="startRecording()">
                    <svg xmlns="http://www.w3.org/2000/svg" class="h-5 w-5 mr-2" viewBox="0 0 20 20" fill="currentColor"><path d="M18 10a8 8 0 11-16 0 8 8 0 0116 0zm-8-3a1 1 0 00-.707 1.707L10.586 10l-3.293 3.293a1 1 0 101.414 1.414l4-4a1 1 0 000-1.414l-4-4A1 1 0 0010 7z"/></svg>
                    <span id="record-text">Start Recording</span>
                </button>

                <button id="stop-button" class="btn-stop flex items-center justify-center font-bold px-6 py-2 rounded-lg disabled:opacity-50" onclick="stopRecording()" disabled>
                    <svg xmlns="http://www.w3.org/2000/svg" class="h-5 w-5 mr-2" viewBox="0 0 20 20" fill="currentColor"><path fill-rule="evenodd" d="M10 18a8 8 0 100-16 8 8 0 000 16zM8 7a1 1 0 00-1 1v4a1 1 0 001 1h4a1 1 0 001-1V8a1 1 0 00-1-1H8z" clip-rule="evenodd"/></svg>
                    Stop Recording
                </button>
            </div>

            <audio id="audio-playback" controls class="w-full mt-2 hidden"></audio>

            <button id="submit-audio-button" class="btn-primary flex items-center justify-center font-bold px-6 py-2 rounded-lg w-full mt-4 disabled:opacity-50" onclick="submitAudioForCorrection()" disabled>
                <span id="correction-loader" class="hidden loader mr-2"></span>
                <svg id="correction-icon" xmlns="http://www.w3.org/2000/svg" class="h-5 w-5 mr-2" viewBox="0 0 20 20" fill="currentColor"><path d="M7 3a1 1 0 000 2h6a1 1 0 100-2H7zM4 7a1 1 0 011-1h10a1 1 0 110 2H5a1 1 0 01-1-1zm3 5a1 1 0 100 2h6a1 1 0 100-2H7z"/></svg>
                <span>Analyze Pronunciation</span>
            </button>

            <!-- Correction Feedback Area -->
            <div id="feedback-area" class="mt-6 p-4 border-l-4 rounded-lg hidden">
                <h3 id="feedback-title" class="text-lg font-semibold">AI Feedback:</h3>
                
                <!-- Target phrase is now always displayed here -->
                <p id="target-phrase-display" class="text-sm mt-2 italic font-semibold"></p> 
                
                <!-- This container now ALWAYS holds the audio player and its label -->
                <div id="correct-audio-container" class="mt-4 p-3 border-t">
                    <p id="correct-audio-label" class="text-sm font-semibold mb-2"></p>
                    <audio id="correct-audio-playback" controls class="w-full"></audio>
                </div>
                
                <div id="correction-output" class="text-gray-700 mt-4"></div>
            </div>
        </div>
    </div>

    <script type="module">
        // Global variables provided by the Canvas environment
        const appId = typeof __app_id !== 'undefined' ? __app_id : 'default-app-id';
        
        // IMPORTANT: The apiKey MUST be an empty string for the environment to inject the key during runtime.
        const apiKey = "" 
        const ttsModel = 'gemini-2.5-flash-preview-tts';
        const correctionModel = 'gemini-2.5-flash-preview-09-2025';
        const apiUrlBase = "https://generativelanguage.googleapis.com/v1beta/models";

        // --- Global Audio URL Management ---
        let userAudioUrl = null;
        let correctAudioUrl = null;

        function revokeObjectUrls() {
            // Revokes all currently tracked Blob URLs to prevent resource conflicts
            if (userAudioUrl) {
                URL.revokeObjectURL(userAudioUrl);
                userAudioUrl = null;
            }
            if (correctAudioUrl) {
                URL.revokeObjectURL(correctAudioUrl);
                correctAudioUrl = null;
            }
        }
        
        // --- Core Utility Functions ---

        function updateStatus(message, isError = false) {
            const statusEl = document.getElementById('status-message');
            statusEl.textContent = message;
            statusEl.className = `mt-4 text-sm font-medium ${isError ? 'text-red-600' : 'text-green-600'}`;
        }

        /** Converts a Base64 string to an ArrayBuffer. */
        function base64ToArrayBuffer(base64) {
            const binary_string = window.atob(base64);
            const len = binary_string.length;
            const bytes = new Uint8Array(len);
            for (let i = 0; i < len; i++) {
                bytes[i] = binary_string.charCodeAt(i);
            }
            return bytes.buffer;
        }

        /**
         * Converts raw signed 16-bit PCM audio data to a standard WAV Blob.
         * The TTS API returns L16 audio data.
         */
        function pcmToWav(pcm16, sampleRate = 24000) {
            const numChannels = 1;
            const bytesPerSample = 2;
            const blockAlign = numChannels * bytesPerSample;
            const byteRate = sampleRate * blockAlign;
            const dataLength = pcm16.length * bytesPerSample;

            const buffer = new ArrayBuffer(44 + dataLength);
            const view = new DataView(buffer);

            // Helper to write a string to the DataView
            const writeString = (view, offset, string) => {
                for (let i = 0; i < string.length; i++) {
                    view.setUint8(offset + i, string.charCodeAt(i));
                }
            };

            let offset = 0;

            // 1. RIFF chunk descriptor
            writeString(view, offset, 'RIFF'); offset += 4; // ChunkID
            view.setUint32(offset, 36 + dataLength, true); offset += 4; // ChunkSize
            writeString(view, offset, 'WAVE'); offset += 4; // Format

            // 2. 'fmt ' sub-chunk
            writeString(view, offset, 'fmt '); offset += 4; // Subchunk1ID
            view.setUint32(offset, 16, true); offset += 4; // Subchunk1Size (16 for PCM)
            view.setUint16(offset, 1, true); offset += 2; // AudioFormat (1 for PCM)
            view.setUint16(offset, numChannels, true); offset += 2; // NumChannels
            view.setUint32(offset, sampleRate, true); offset += 4; // SampleRate
            view.setUint32(offset, byteRate, true); offset += 4; // ByteRate
            view.setUint16(offset, blockAlign, true); offset += 2; // BlockAlign
            view.setUint16(offset, bytesPerSample * 8, true); offset += 2; // BitsPerSample (16)

            // 3. 'data' sub-chunk
            writeString(view, offset, 'data'); offset += 4; // Subchunk2ID
            view.setUint32(offset, dataLength, true); offset += 4; // Subchunk2Size

            // Write the PCM data
            for (let i = 0; i < pcm16.length; i++) {
                view.setInt16(offset, pcm16[i], true);
                offset += 2;
            }

            return new Blob([buffer], { type: 'audio/wav' });
        }


        /**
         * Generates TTS audio, applying stabilization hacks and retry logic internally.
         * @param {string} text The text prompt for TTS.
         * @param {string} voiceName The voice to use.
         * @param {HTMLAudioElement} audioElement The element to assign the generated audio to.
         * @param {number} maxRetries The maximum number of retry attempts.
         */
        async function generateTtsAudio(text, voiceName, audioElement, maxRetries = 5) {
            if (!text || text.trim().length === 0) {
                throw new Error("TTS generation skipped: Input text is empty.");
            }
            
            // --- TTS STABILIZATION LOGIC (Applied only to the API payload) ---
            let phraseForTTS = text;
            const minimumLengthForPrefix = 10;
            
            // 1. Stabilization Prefix: For very short phrases, prepend a subtle instructional phrase.
            if (phraseForTTS.length < minimumLengthForPrefix) { 
                phraseForTTS = `The phrase is, ${phraseForTTS}`; 
            }
            
            // 2. Terminal Punctuation: Ensure terminal punctuation exists for API stability.
            if (!/[.?!]$/.test(phraseForTTS)) {
                phraseForTTS += '.';
            }
            // --- END STABILIZATION LOGIC ---

            console.log(`TTS Request: Generating audio for text: "${text}" (API Payload: "${phraseForTTS}") with voice: ${voiceName}`);

            const url = `${apiUrlBase}/${ttsModel}:generateContent?key=${apiKey}`;

            const payload = {
                contents: [{ parts: [{ text: phraseForTTS }] }],
                generationConfig: {
                    responseModalities: ["AUDIO"],
                    speechConfig: {
                        voiceConfig: {
                            prebuiltVoiceConfig: { voiceName: voiceName }
                        }
                    }
                },
                model: ttsModel
            };

            for (let attempt = 0; attempt < maxRetries; attempt++) {
                try {
                    const response = await fetch(url, {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify(payload)
                    });

                    const result = await response.json();
                    
                    if (!response.ok) {
                        const errorMsg = result.error?.message || `API call failed with status ${response.status}.`;
                        console.error(`Attempt ${attempt + 1} failed: ${errorMsg}`, result);
                        if (attempt === maxRetries - 1) {
                            throw new Error(`TTS API failed to authenticate or respond: ${errorMsg}`);
                        }
                        // Continue to backoff/retry
                    } else {
                        // Look for the audio part with the L16 MIME type
                        const candidate = result.candidates?.[0];
                        const part = candidate?.content?.parts?.find(p => p.inlineData && p.inlineData.mimeType.startsWith('audio/L16'));

                        if (!part || !part.inlineData || !part.inlineData.data) {
                            console.error(`Attempt ${attempt + 1} failed: TTS API Response missing audio data.`, result);
                            if (attempt === maxRetries - 1) { 
                                throw new Error("TTS model could not generate audio. The text may be too short or flagged.");
                            }
                            // Continue to backoff/retry
                        } else {
                            // Success path
                            const audioData = part.inlineData.data;
                            const mimeType = part.inlineData.mimeType;
                            
                            const rateMatch = mimeType.match(/rate=(\d+)/);
                            const sampleRate = rateMatch ? parseInt(rateMatch[1], 10) : 24000;

                            const pcmData = base64ToArrayBuffer(audioData); 
                            const pcm16 = new Int16Array(pcmData);
                            
                            const wavBlob = pcmToWav(pcm16, sampleRate);
                            const audioUrl = URL.createObjectURL(wavBlob);
                            
                            // If this is the dedicated correct audio element, manage its URL globally
                            if (audioElement.id === 'correct-audio-playback') {
                                if (correctAudioUrl) URL.revokeObjectURL(correctAudioUrl); // Revoke old one
                                correctAudioUrl = audioUrl; // Store new one
                            }

                            audioElement.src = audioUrl;
                            audioElement.load(); 
                            return; // Exit successfuly
                        }
                    }

                } catch (error) {
                    console.error(`Attempt ${attempt + 1} failed with unhandled error.`, error);
                    if (attempt === maxRetries - 1) {
                        throw error;
                    }
                }

                // Exponential backoff
                const delay = Math.pow(2, attempt) * 1000 + (Math.random() * 500); 
                console.warn(`Retrying TTS in ${Math.ceil(delay / 1000)}s...`);
                await new Promise(resolve => setTimeout(resolve, delay));
            }
        }

        // --- Section 1: AI Speaks (TTS) ---

        window.speakText = async function() {
            const text = document.getElementById('tts-input').value.trim();
            const voiceName = document.getElementById('voice-select').value;
            const ttsButton = document.getElementById('tts-button');
            const loader = document.getElementById('tts-loader');
            const icon = document.getElementById('tts-icon');
            const tempAudio = new Audio(); // Use temporary audio element for playback

            if (!text) {
                updateStatus("Please enter some text for the AI to speak.", true);
                return;
            }

            // Sanitize text for TTS (removing confusing symbols but keeping basic punctuation)
            const cleanText = text.replace(/[^a-zA-Z0-9\s.,?!]/g, '').trim();
            
            if (cleanText.length < 3) {
                 updateStatus("Text is too short for speech generation (minimum 3 characters required after cleanup).", true);
                 return;
            }
            
            ttsButton.disabled = true;
            icon.classList.add('hidden');
            loader.classList.remove('hidden');
            updateStatus("Generating speech, please wait...");

            try {
                // generateTtsAudio handles stabilization and retries internally
                await generateTtsAudio(cleanText, voiceName, tempAudio);

                tempAudio.play();
                updateStatus("Audio is playing!");
                tempAudio.onended = () => {
                     updateStatus("AI finished speaking. Try repeating the phrase!");
                };

            } catch (error) {
                console.error("TTS Error:", error);
                updateStatus(`Error generating speech: ${error.message}.`, true);
            } finally {
                ttsButton.disabled = false;
                loader.classList.add('hidden');
                icon.classList.remove('hidden');
            }
        }

        // --- Section 2: User Speaks (ASR & Correction) ---

        let mediaRecorder;
        let audioChunks = [];
        let finalAudioBlob = null;
        let recordingStartTime;

        const recordButton = document.getElementById('record-button');
        const stopButton = document.getElementById('stop-button');
        const submitButton = document.getElementById('submit-audio-button');
        const audioPlayback = document.getElementById('audio-playback');
        
        const feedbackArea = document.getElementById('feedback-area');
        const feedbackTitle = document.getElementById('feedback-title');
        const correctionOutput = document.getElementById('correction-output');
        
        // UI elements
        const targetPhraseDisplay = document.getElementById('target-phrase-display');
        const correctAudioContainer = document.getElementById('correct-audio-container');
        const correctAudioPlayback = document.getElementById('correct-audio-playback');
        const correctAudioLabel = document.getElementById('correct-audio-label');
        
        const recordText = document.getElementById('record-text');

        // Function to convert Blob to Base64
        function blobToBase64(blob) {
            return new Promise((resolve, reject) => {
                const reader = new FileReader();
                reader.onloadend = () => {
                    // Extract the base64 part (remove the data URI prefix)
                    const base64String = reader.result.split(',')[1];
                    resolve(base64String);
                };
                reader.onerror = reject;
                reader.readAsDataURL(blob);
            });
        }
        
        /**
         * Checks the current microphone permission status and updates the UI accordingly.
         * @returns {boolean} True if recording can proceed (prompt or granted), False if blocked.
         */
        async function checkMicrophonePermission() {
            const statusEl = document.getElementById('status-message');
            try {
                const permissionStatus = await navigator.permissions.query({ name: 'microphone' });

                if (permissionStatus.state === 'denied') {
                    recordButton.disabled = true;
                    submitButton.disabled = true;
                    statusEl.innerHTML = `
                        <div class="p-3 bg-red-100 border border-red-300 rounded-lg">
                            <p class="text-base text-red-700 font-bold">‚ö†Ô∏è Microphone Access Blocked</p>
                            <p class="text-sm text-red-600 mt-1">Your browser settings are permanently blocking microphone access for this site. Because you previously denied it, the browser will not prompt you again.</p>
                            <p class="text-sm text-red-600 mt-2 font-bold">To fix this, you must manually go to your browser's site settings and change the microphone permission from 'Block' to 'Ask' or 'Allow'.</p>
                        </div>
                    `;
                    return false;
                } else if (permissionStatus.state === 'prompt') {
                    statusEl.textContent = "Microphone ready to be requested. Click 'Start Recording' to see the browser prompt.";
                    recordButton.disabled = false;
                } else if (permissionStatus.state === 'granted') {
                    statusEl.textContent = "Microphone access is already granted! Click 'Start Recording' to begin.";
                    recordButton.disabled = false;
                }
                return true;
            } catch (e) {
                // Fallback for browsers that don't support navigator.permissions.query
                console.warn("Could not query microphone permission status, falling back to attempting access:", e);
                statusEl.textContent = "Microphone status uncertain. Click 'Start Recording' to test access.";
                return true; 
            }
        }


        window.startRecording = async function() {
            // Check permission status before trying to record
            const canProceed = await checkMicrophonePermission();
            if (!canProceed) {
                return;
            }

            try {
                // IMPORTANT: Revoke all old Blob URLs before starting a new recording process
                revokeObjectUrls();

                // Request microphone access
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });

                audioChunks = [];
                finalAudioBlob = null;
                audioPlayback.src = '';
                audioPlayback.classList.add('hidden');
                feedbackArea.classList.add('hidden');
                correctionOutput.textContent = '';
                correctAudioPlayback.src = ''; // Clear correct audio source
                
                // Set initial status for correction audio
                correctAudioContainer.classList.remove('hidden'); 
                correctAudioLabel.textContent = "Waiting for analysis to generate correct pronunciation...";


                mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm' });

                mediaRecorder.ondataavailable = event => {
                    audioChunks.push(event.data);
                };

                mediaRecorder.onstop = () => {
                    finalAudioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                    
                    // Store the user audio URL globally and assign
                    userAudioUrl = URL.createObjectURL(finalAudioBlob);
                    audioPlayback.src = userAudioUrl;

                    audioPlayback.classList.remove('hidden');
                    submitButton.disabled = false;
                    recordButton.disabled = false;
                    recordButton.classList.remove('recording-active');
                    recordText.textContent = 'Record Again';
                    stream.getTracks().forEach(track => track.stop()); // Stop the mic stream
                    const duration = ((Date.now() - recordingStartTime) / 1000).toFixed(1);
                    updateStatus(`Recording stopped. Duration: ${duration}s. Press 'Analyze Pronunciation' for feedback.`);
                };

                mediaRecorder.start();
                recordingStartTime = Date.now();
                submitButton.disabled = true;
                recordButton.disabled = true;
                stopButton.disabled = false;
                recordButton.classList.add('recording-active');
                recordText.textContent = 'Recording...';
                updateStatus("Recording started. Please speak clearly.");

            } catch (error) {
                console.error("Microphone access error:", error);
                // Simple error message here, as checkMicrophonePermission handles the detailed block message
                if (error.name === "NotAllowedError" || error.message.includes("Permission denied")) {
                    updateStatus("Microphone access was denied. Please ensure you click 'Allow' in the browser pop-up.", true);
                    recordButton.disabled = false; // Allow user to try again
                } else {
                    updateStatus(`Error accessing microphone: ${error.message}.`, true);
                    recordButton.disabled = false; // Allow user to try again
                }
            }
        }

        window.stopRecording = function() {
            if (mediaRecorder && mediaRecorder.state === 'recording') {
                mediaRecorder.stop();
                stopButton.disabled = true;
            }
        }

        /**
         * Cleans a string for TTS/ASR by removing characters that often confuse the models.
         * @param {string} text - The input phrase.
         * @returns {string} - The sanitized phrase.
         */
        function sanitizeText(text) {
             // Keep alphanumeric characters, spaces, and standard punctuation (. , ? !)
            return text.replace(/[^a-zA-Z0-9\s.,?!]/g, '').trim();
        }


        window.submitAudioForCorrection = async function() {
            if (!finalAudioBlob) {
                updateStatus("Please record your speech first.", true);
                return;
            }
            
            // --- Sanity check for small/empty audio file ---
            if (finalAudioBlob.size < 1024) { // Check if file is less than 1KB
                updateStatus("Recorded audio file is too small. Please ensure your microphone is working and you spoke for at least 1 second.", true);
                submitButton.disabled = false;
                recordButton.disabled = false;
                return;
            }

            submitButton.disabled = true;
            recordButton.disabled = true;
            const loader = document.getElementById('correction-loader');
            const icon = document.getElementById('correction-icon');
            
            // Hide previous results and clear state
            icon.classList.add('hidden');
            loader.classList.remove('hidden');
            feedbackArea.classList.add('hidden');
            correctionOutput.textContent = '';
            
            // Prepare for correction audio generation status
            correctAudioPlayback.src = ''; 
            correctAudioContainer.classList.remove('hidden'); 
            correctAudioLabel.textContent = "AI is analyzing your speech...";
            
            updateStatus("Analyzing pronunciation with AI, this may take a moment...");

            let parsedJson;
            let jsonText; 

            try {
                // 1. Convert audio blob to Base64
                const base64Audio = await blobToBase64(finalAudioBlob);

                // 2. Define the JSON schema for structured correction output
                const CorrectionSchema = {
                    type: "OBJECT",
                    properties: {
                        targetPhrase: {
                            type: "STRING",
                            description: "The full, correctly spelled phrase the user was attempting to say. This should be the text the user should practice."
                        },
                        feedback: {
                            type: "STRING",
                            description: "Detailed, constructive feedback on accent, intonation, and clarity, provided in plain text. Include the full transcription of what you heard in this field."
                        },
                        isPronunciationCorrect: {
                            type: "BOOLEAN",
                            description: "Set to true if the transcription closely matches the target phrase and the pronunciation is excellent, otherwise false."
                        }
                    },
                    propertyOrdering: ["targetPhrase", "feedback", "isPronunciationCorrect"]
                };

                // 3. Prepare the API payload for multimodal call with structured output
                const systemPrompt = "You are an expert English pronunciation coach. Analyze the provided audio recording. Provide a friendly, constructive, and detailed response in the requested JSON format. The 'targetPhrase' must be the correctly spelled version of the sentence the user was trying to say. The 'feedback' must be provided in PLAIN TEXT without any markdown elements (no bolding, no italics, no headings like # or **). Set 'isPronunciationCorrect' to true if the pronunciation is nearly perfect, otherwise false.";
                const userQuery = "Analyze the pronunciation and provide detailed correction feedback for this audio. Focus on the clarity and accent, and identify the target phrase I was trying to say.";
                const apiUrl = `${apiUrlBase}/${correctionModel}:generateContent?key=${apiKey}`;

                const payload = {
                    contents: [{
                        parts: [
                            { text: userQuery },
                            {
                                inlineData: {
                                    mimeType: 'audio/webm',
                                    data: base64Audio
                                }
                            }
                        ]
                    }],
                    systemInstruction: { parts: [{ text: systemPrompt }] },
                    generationConfig: {
                        responseMimeType: "application/json",
                        responseSchema: CorrectionSchema
                    }
                };

                // 4. Call the Correction API
                const response = await fetch(apiUrl, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(payload)
                });

                const result = await response.json();
                
                // --- NEW: Handle 403 Authentication Error explicitly ---
                if (!response.ok) {
                    if (response.status === 403) {
                         throw new Error("Authentication Failed (403). The API key was rejected. This is usually an environmental issue. Please try again in a moment.");
                    }
                    const errorMsg = result.error?.message || `API call failed with status ${response.status}.`;
                    console.error("API Call Error Details:", result);
                    throw new Error(errorMsg);
                }
                
                jsonText = result.candidates?.[0]?.content?.parts?.[0]?.text;
                if (!jsonText) {
                     // Handle the case where the status is OK but the content is empty
                     console.error("AI returned empty content or structure in candidates part.", result);
                     throw new Error("AI returned empty content or structure.");
                }
                
                // Robustly strip markdown and preambles from the JSON string
                jsonText = jsonText.trim();
                jsonText = jsonText.replace(/^```(json|JSON)?\s*/, '');
                jsonText = jsonText.replace(/\s*```$/, '');
                jsonText = jsonText.trim(); 
                
                parsedJson = JSON.parse(jsonText);

                const { targetPhrase, feedback, isPronunciationCorrect } = parsedJson;
                const isCorrect = isPronunciationCorrect === true;

                if (targetPhrase && feedback) {
                    // Set colors and title
                    const bgColor = isCorrect ? 'bg-green-50' : 'bg-yellow-50';
                    const borderColor = isCorrect ? 'border-green-500' : 'border-yellow-500';
                    const titleColor = isCorrect ? 'text-green-800' : 'text-yellow-800';
                    const phraseColor = isCorrect ? 'text-green-700' : 'text-yellow-700';
                    const titleText = isCorrect ? 'Great Job! Pronunciation Correct' : 'Needs Practice: AI Feedback';

                    // 5. Apply main feedback area styling
                    feedbackArea.className = `mt-6 p-4 border-l-4 rounded-lg ${bgColor} ${borderColor}`;
                    feedbackArea.classList.remove('hidden');

                    // 6. Apply title styling and text
                    feedbackTitle.className = `text-lg font-semibold ${titleColor}`;
                    feedbackTitle.textContent = titleText;
                    
                    // 7. Set and display the Target Phrase (ALWAYS VISIBLE)
                    targetPhraseDisplay.textContent = `Target Phrase: "${targetPhrase}"`;
                    targetPhraseDisplay.className = `text-sm mt-2 italic font-semibold ${phraseColor}`;
                    
                    // 8. Display the text feedback
                    correctionOutput.textContent = feedback;
                    
                    // 9. Prepare for Correct Pronunciation Audio Generation
                    correctAudioContainer.classList.remove('hidden'); 
                    correctAudioLabel.textContent = "Generating correct pronunciation...";
                    correctAudioContainer.classList.add('border-t', 'p-3', isCorrect ? 'border-green-200' : 'border-yellow-200');
                    correctAudioLabel.classList.add(isCorrect ? 'text-green-700' : 'text-yellow-700');


                    // 10. Always attempt to generate correct audio if a target phrase exists
                    updateStatus(`Analysis complete. Now generating correct audio for reference...`);
                    
                    const cleanTargetPhrase = sanitizeText(targetPhrase);
                    
                    if (!cleanTargetPhrase || cleanTargetPhrase.trim().length < 3) { 
                        correctAudioLabel.textContent = "Error: Cannot generate audio. The identified practice phrase is too short (min 3 characters).";
                        correctAudioPlayback.src = ''; 
                        updateStatus(`Analysis complete, but failed to generate correction audio: The practice phrase is too short.`, true);
                        return; 
                    }
                    
                    try {
                        // Generate and display the correct audio using the stabilized, retrying function
                        await generateTtsAudio(cleanTargetPhrase, 'Kore', correctAudioPlayback);
                        
                        // Final status update
                        updateStatus(isCorrect ? "Fantastic! Your pronunciation was clear and accurate. Listen to the AI's pronunciation for reference." : "Analysis and correction audio complete! Listen and practice.");
                        
                    } catch (ttsError) {
                        console.error("Correction TTS Error:", ttsError);
                        
                        // Handle failure gracefully
                        correctAudioLabel.textContent = `Error: Could not generate correct audio. (${ttsError.message})`;
                        correctAudioPlayback.src = '';
                        updateStatus(`Analysis complete, but failed to generate correction audio: ${ttsError.message}`, true);
                    }
                    
                } else {
                    throw new Error("AI returned an incomplete correction structure (missing targetPhrase or feedback).");
                }

            } catch (error) {
                console.error("Analysis Error:", error);
                
                // --- Updated message for 403 error ---
                let displayMessage = `Sorry, an error occurred during analysis: ${error.message}.`;
                if (error.message.includes("403")) {
                    displayMessage = "Authentication Error (403): The system failed to load the necessary credentials. Please refresh the page and try again.";
                }
                
                correctionOutput.textContent = displayMessage;
                feedbackArea.classList.remove('hidden');
                updateStatus("Failed to analyze audio. Please try recording again or check the console.", true);
            } finally {
                submitButton.disabled = false;
                recordButton.disabled = false;
                loader.classList.add('hidden');
                icon.classList.remove('hidden');
            }
        }
        
        // --- Run Initial Check on Load ---
        window.onload = function() {
            // Check microphone status immediately when the page loads
            checkMicrophonePermission(); 
        };

    </script>
</body>
</html>
